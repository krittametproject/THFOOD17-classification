{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cabe7a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untitled.ipynb\t   dataset-food17      result_svm.csv  tutorials\n",
      "data_explor.ipynb  foodclassify.ipynb  src\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "164d17e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader as dalo\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "236ff077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /home/jupyter/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d288d540f334946ae82721ada110ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/83.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resnet34 = models.resnet34(pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20436877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########  START TRAINING  ##########\n",
      "1 from 80 || Training Loss: 0.136844 || Valid Loss: 2.68926 || train Accuracy: 22.1504% || Valid Accuracy: 23.1018%\n",
      "**Valid loss decrease from inf --> 2.68926. Saving model ...\n",
      "2 from 80 || Training Loss: 0.133103 || Valid Loss: 2.68002 || train Accuracy: 27.4859% || Valid Accuracy: 24.3942%\n",
      "**Valid loss decrease from 2.68926 --> 2.68002. Saving model ...\n",
      "3 from 80 || Training Loss: 0.130586 || Valid Loss: 2.57864 || train Accuracy: 34.0744% || Valid Accuracy: 36.0258%\n",
      "**Valid loss decrease from 2.68002 --> 2.57864. Saving model ...\n",
      "4 from 80 || Training Loss: 0.128135 || Valid Loss: 2.57319 || train Accuracy: 40.0162% || Valid Accuracy: 38.4491%\n",
      "**Valid loss decrease from 2.57864 --> 2.57319. Saving model ...\n",
      "5 from 80 || Training Loss: 0.126747 || Valid Loss: 2.54407 || train Accuracy: 42.3605% || Valid Accuracy: 39.2569%\n",
      "**Valid loss decrease from 2.57319 --> 2.54407. Saving model ...\n",
      "6 from 80 || Training Loss: 0.125136 || Valid Loss: 2.51605 || train Accuracy: 45.0283% || Valid Accuracy: 42.6494%\n",
      "**Valid loss decrease from 2.54407 --> 2.51605. Saving model ...\n",
      "7 from 80 || Training Loss: 0.124561 || Valid Loss: 2.57613 || train Accuracy: 45.8367% || Valid Accuracy: 35.2181%\n",
      "8 from 80 || Training Loss: 0.123429 || Valid Loss: 2.44941 || train Accuracy: 48.9895% || Valid Accuracy: 49.1115%\n",
      "**Valid loss decrease from 2.51605 --> 2.44941. Saving model ...\n",
      "9 from 80 || Training Loss: 0.122298 || Valid Loss: 2.44533 || train Accuracy: 50.9701% || Valid Accuracy: 48.7884%\n",
      "**Valid loss decrease from 2.44941 --> 2.44533. Saving model ...\n",
      "10 from 80 || Training Loss: 0.12173 || Valid Loss: 2.56994 || train Accuracy: 51.9806% || Valid Accuracy: 35.7027%\n",
      "11 from 80 || Training Loss: 0.121263 || Valid Loss: 2.44115 || train Accuracy: 52.4252% || Valid Accuracy: 50.2423%\n",
      "**Valid loss decrease from 2.44533 --> 2.44115. Saving model ...\n",
      "12 from 80 || Training Loss: 0.12041 || Valid Loss: 2.4214 || train Accuracy: 54.8504% || Valid Accuracy: 52.1809%\n",
      "**Valid loss decrease from 2.44115 --> 2.4214. Saving model ...\n",
      "13 from 80 || Training Loss: 0.120119 || Valid Loss: 2.40352 || train Accuracy: 54.6079% || Valid Accuracy: 53.958%\n",
      "**Valid loss decrease from 2.4214 --> 2.40352. Saving model ...\n",
      "14 from 80 || Training Loss: 0.119694 || Valid Loss: 2.39425 || train Accuracy: 55.578% || Valid Accuracy: 54.2811%\n",
      "**Valid loss decrease from 2.40352 --> 2.39425. Saving model ...\n",
      "15 from 80 || Training Loss: 0.119292 || Valid Loss: 2.46837 || train Accuracy: 56.7502% || Valid Accuracy: 47.0113%\n",
      "16 from 80 || Training Loss: 0.118453 || Valid Loss: 2.4056 || train Accuracy: 58.3266% || Valid Accuracy: 53.7964%\n",
      "17 from 80 || Training Loss: 0.117423 || Valid Loss: 2.39926 || train Accuracy: 60.3476% || Valid Accuracy: 53.6349%\n",
      "18 from 80 || Training Loss: 0.117307 || Valid Loss: 2.40354 || train Accuracy: 60.7518% || Valid Accuracy: 54.1195%\n",
      "19 from 80 || Training Loss: 0.116776 || Valid Loss: 2.35627 || train Accuracy: 61.6815% || Valid Accuracy: 58.643%\n",
      "**Valid loss decrease from 2.39425 --> 2.35627. Saving model ...\n",
      "20 from 80 || Training Loss: 0.115766 || Valid Loss: 2.33023 || train Accuracy: 63.0558% || Valid Accuracy: 62.1971%\n",
      "**Valid loss decrease from 2.35627 --> 2.33023. Saving model ...\n",
      "21 from 80 || Training Loss: 0.115653 || Valid Loss: 2.43828 || train Accuracy: 63.46% || Valid Accuracy: 49.4346%\n",
      "22 from 80 || Training Loss: 0.114835 || Valid Loss: 2.34831 || train Accuracy: 65.4406% || Valid Accuracy: 58.8045%\n",
      "23 from 80 || Training Loss: 0.114138 || Valid Loss: 2.31176 || train Accuracy: 66.734% || Valid Accuracy: 64.1357%\n",
      "**Valid loss decrease from 2.33023 --> 2.31176. Saving model ...\n",
      "24 from 80 || Training Loss: 0.115147 || Valid Loss: 2.28569 || train Accuracy: 64.0663% || Valid Accuracy: 65.7512%\n",
      "**Valid loss decrease from 2.31176 --> 2.28569. Saving model ...\n",
      "25 from 80 || Training Loss: 0.11452 || Valid Loss: 2.29553 || train Accuracy: 65.5618% || Valid Accuracy: 64.2973%\n",
      "26 from 80 || Training Loss: 0.113929 || Valid Loss: 2.31144 || train Accuracy: 66.7745% || Valid Accuracy: 63.0048%\n",
      "27 from 80 || Training Loss: 0.113247 || Valid Loss: 2.29421 || train Accuracy: 68.1892% || Valid Accuracy: 64.4588%\n",
      "28 from 80 || Training Loss: 0.113735 || Valid Loss: 2.27316 || train Accuracy: 66.8149% || Valid Accuracy: 66.8821%\n",
      "**Valid loss decrease from 2.28569 --> 2.27316. Saving model ...\n",
      "29 from 80 || Training Loss: 0.113326 || Valid Loss: 2.30755 || train Accuracy: 68.1487% || Valid Accuracy: 62.6817%\n",
      "30 from 80 || Training Loss: 0.112686 || Valid Loss: 2.30255 || train Accuracy: 69.6847% || Valid Accuracy: 64.1357%\n",
      "31 from 80 || Training Loss: 0.112207 || Valid Loss: 2.3487 || train Accuracy: 70.3314% || Valid Accuracy: 58.3199%\n",
      "32 from 80 || Training Loss: 0.112325 || Valid Loss: 2.30708 || train Accuracy: 70.0485% || Valid Accuracy: 63.6511%\n",
      "33 from 80 || Training Loss: 0.112264 || Valid Loss: 2.26412 || train Accuracy: 69.9272% || Valid Accuracy: 67.5283%\n",
      "**Valid loss decrease from 2.27316 --> 2.26412. Saving model ...\n",
      "34 from 80 || Training Loss: 0.111662 || Valid Loss: 2.3273 || train Accuracy: 71.5441% || Valid Accuracy: 60.7431%\n",
      "35 from 80 || Training Loss: 0.111872 || Valid Loss: 2.38326 || train Accuracy: 70.7761% || Valid Accuracy: 56.2197%\n",
      "36 from 80 || Training Loss: 0.11149 || Valid Loss: 2.3619 || train Accuracy: 72.1908% || Valid Accuracy: 57.6737%\n",
      "37 from 80 || Training Loss: 0.111653 || Valid Loss: 2.26912 || train Accuracy: 71.2207% || Valid Accuracy: 67.5283%\n",
      "38 from 80 || Training Loss: 0.110975 || Valid Loss: 2.36578 || train Accuracy: 72.2716% || Valid Accuracy: 57.3506%\n",
      "39 from 80 || Training Loss: 0.110015 || Valid Loss: 2.24886 || train Accuracy: 74.9394% || Valid Accuracy: 69.9515%\n",
      "**Valid loss decrease from 2.26412 --> 2.24886. Saving model ...\n",
      "40 from 80 || Training Loss: 0.109376 || Valid Loss: 2.24947 || train Accuracy: 76.637% || Valid Accuracy: 69.79%\n",
      "41 from 80 || Training Loss: 0.109466 || Valid Loss: 2.27208 || train Accuracy: 75.9095% || Valid Accuracy: 66.559%\n"
     ]
    }
   ],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "      super(CNN, self).__init__()\n",
    "      self.resnet34 = models.resnet34(pretrained=True).to(device)\n",
    "      self.conv1 = self.resnet34.conv1\n",
    "      self.bn1 = self.resnet34.bn1\n",
    "      self.relu = self.resnet34.relu\n",
    "      self.maxpool = self.resnet34.maxpool\n",
    "      self.layer1 = self.resnet34.layer1\n",
    "      self.layer2 = self.resnet34.layer2\n",
    "      self.layer3 = self.resnet34.layer3\n",
    "      self.layer4 = self.resnet34.layer4\n",
    "      self.avgpool = self.resnet34.avgpool\n",
    "      self.fc1 = torch.nn.Linear(128,17, bias=False)\n",
    "  \n",
    "  def forward(self, x):\n",
    "      relu = torch.nn.ReLU()\n",
    "      softmax = torch.nn.Softmax(dim=1)\n",
    "      x = x.to(device)\n",
    "      x = self.conv1(x)\n",
    "      x = self.bn1(x)\n",
    "      x = self.relu(x)\n",
    "      x = self.maxpool(x)\n",
    "      x = self.layer1(x)\n",
    "      x = self.layer2(x)\n",
    "      x = self.avgpool(x)\n",
    "      x = torch.flatten(x, 1)\n",
    "      x = softmax(self.fc1(x))\n",
    "      return x\n",
    "\n",
    "def load_data(path='', batch=30, transform=None):\n",
    "    train_dataset = datasets.ImageFolder(path+'/train', transform=transform)\n",
    "    test_dataset = datasets.ImageFolder(path+'/test', transform=transform)\n",
    "    n_train = round(len(train_dataset)*0.8)\n",
    "    train_data, valid_data = random_split(train_dataset, [n_train, len(train_dataset)-n_train])\n",
    "    train_set = dalo(train_data, batch_size=batch, shuffle=True)\n",
    "    valid_set = dalo(valid_data)\n",
    "    test_set = dalo(test_dataset)\n",
    "    return train_set, valid_set, test_set\n",
    "\n",
    "def train_(model, train_set, valid_set,epochs, model_num, lr, b):\n",
    "  _, ((ax1), (ax2)) = plt.subplots(nrows=1,ncols=2)\n",
    "  train_loss_tmp = []\n",
    "  valid_loss_tmp = []\n",
    "  accuracy_valid_tmp = []\n",
    "  accuracy_train_tmp = []\n",
    "  criterion = torch.nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "  valid_loss_min = np.Inf\n",
    "  print('##########  START TRAINING  ##########')\n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_size = 0\n",
    "    train_loss = 0\n",
    "    correct_train = 0\n",
    "    for data, label in train_set:\n",
    "      train_size += data.shape[0]\n",
    "      data = data.type(torch.float32).to(device)\n",
    "      label = label.type(torch.float32).to(device)\n",
    "      optimizer.zero_grad()\n",
    "      output = model(data)\n",
    "      _, predict = output.max(1)\n",
    "      correct_train += predict.eq(label).sum().item()\n",
    "      loss = criterion(output, label.long())\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      train_loss += loss.item()\n",
    "    accuracy_train_tmp.append(100.*correct_train/train_size)\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    with torch.no_grad():\n",
    "      valid_size = 0\n",
    "      correct_valid = 0\n",
    "      for data, label in valid_set:\n",
    "        valid_size += data.shape[0]\n",
    "        data = data.type(torch.float32).to(device)\n",
    "        label = label.type(torch.float32).to(device)\n",
    "        output = model(data)\n",
    "        _, predict = output.max(1)\n",
    "        #print('predict{} -- label{}'(predict))\n",
    "        correct_valid += predict.eq(label).sum().item()\n",
    "        loss = criterion(output, label.long())\n",
    "        valid_loss += loss.item()\n",
    "        # print('train_loss', train_loss)\n",
    "        # print('valid loss', valid_loss)\n",
    "      train_loss = train_loss/train_size\n",
    "      valid_loss = valid_loss/valid_size\n",
    "      valid_loss_tmp.append(valid_loss)\n",
    "      train_loss_tmp.append(train_loss)\n",
    "      accuracy_valid_tmp.append(100.*correct_valid/valid_size)\n",
    "      model_save = 'model_e'+str(epochs)+'_b'+str(b)+'_lr'+str(lr)+'.pt'\n",
    "      print('{} from {} || Training Loss: {:.6} || Valid Loss: {:.6} || train Accuracy: {:.6}% || Valid Accuracy: {:.6}%'\\\n",
    "            .format(epoch+1, epochs, train_loss, valid_loss, accuracy_train_tmp[-1], accuracy_valid_tmp[-1]))\n",
    "      if valid_loss <= valid_loss_min:\n",
    "        print('**Valid loss decrease from {:.6} --> {:.6}. Saving model ...'.format(valid_loss_min, valid_loss))\n",
    "        torch.save(model.state_dict(), model_save)\n",
    "        valid_loss_min = valid_loss\n",
    "\n",
    "  ax1.plot(valid_loss_tmp, label='Valid loss')\n",
    "  ax1.plot(train_loss_tmp, label='train loss')\n",
    "  ax2.plot(accuracy_valid_tmp, label='accuracy valid')\n",
    "  ax2.plot(accuracy_train_tmp, label='accuracy train')\n",
    "  ax2.plot()\n",
    "  plt.legend()\n",
    "  plt.title('TH FOOD17'+'model_'+'b'+str(b)+'_lr'+str(lr)+'.pt')\n",
    "  plt.show()\n",
    "  print('########## FINISH TRAINING ##########')\n",
    "\n",
    "def test_(model, test_set):\n",
    "  modelpt = ['./model_e140_b20_lr0.001.pt']\n",
    "  for i in modelpt:\n",
    "    model.load_state_dict(torch.load(i))\n",
    "    accuracy_=0\n",
    "    correct=0\n",
    "    test_size = len(test_set)\n",
    "    with torch.no_grad():\n",
    "      for data, label in test_set:\n",
    "        data = data.type(torch.float32).to(device)\n",
    "        label = label.type(torch.float32).to(device)\n",
    "        output = model(data)\n",
    "        _, predict = output.max(1)\n",
    "        #print('predict{} -- label{}'(predict))\n",
    "        correct+= predict.eq(label).sum().item()\n",
    "      accuracy_ = 100.*correct/test_size\n",
    "      print(i[2:],' accuracy=', accuracy_)\n",
    "\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "  batch=[10,20,30]\n",
    "  epochs = [80,100,120,140]\n",
    "  lr = [0.001, 0.00001]\n",
    "  tran = transforms.Compose( [transforms.Resize((256, 256)),\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                          std=[0.229, 0.224, 0.225])])\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "  model_num = 0\n",
    "  for b in batch:\n",
    "    for e in epochs:\n",
    "      for l in lr:\n",
    "        model_num += 1\n",
    "        train_dataset, valid_dataset, _ = load_data('./dataset-food17',b,transform=tran)\n",
    "        torch.cuda.empty_cache()\n",
    "        model = CNN().to(device)\n",
    "        train_(model, train_dataset, valid_dataset, e, model_num, l, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9436339",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-8.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m71"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
